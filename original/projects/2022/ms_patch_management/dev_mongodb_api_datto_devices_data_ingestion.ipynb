{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1> DattoRMM - Devices - Data Ingestion - MongoDB</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import json\n",
    "\n",
    "\n",
    "# add current timestamp to filename for reference\n",
    "current_time = (dt.datetime.utcnow().strftime('%Y_%m_%d_%H%M%S'))\n",
    "\n",
    "# export folder will contain all csv exported DataFrames for Ticket Creation\n",
    "export_folder = 'd:/exports/'\n",
    "\n",
    "# import configparser for env secrets\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read('d:/git/example_infrastructure_data_dev/config/env.ini')\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DattoRMM - Pull JSON from API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Auth Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create DataFrame via API Call Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DattoRMM DataFrame - import and assign secrets from env.ini\n",
    "base_uri = config['dattormm']['base_uri']\n",
    "api_key = config['dattormm']['api_key']\n",
    "api_secret = config['dattormm']['api_secret']\n",
    "# call token api url\n",
    "token_uri = config['dattormm']['token_uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct header\n",
    "headers = CaseInsensitiveDict()\n",
    "headers['Content-Type'] = 'application/x-www-form-urlencoded'\n",
    "\n",
    "# construct req body\n",
    "data = CaseInsensitiveDict()\n",
    "data['grant_type'] = 'password'\n",
    "data['username'] = api_key\n",
    "data['password'] = api_secret\n",
    "\n",
    "# request content response\n",
    "resp = requests.post(token_uri, headers=headers, data=data, auth=('public-client', 'public'))\n",
    "content = resp.content.decode('utf-8')\n",
    "c_dict = json.loads(content)\n",
    "\n",
    "access_token = c_dict['access_token']\n",
    "## Create Devices DataFrame\n",
    "# request content response\n",
    "request_url = f'{base_uri}/account/devices'\n",
    "\n",
    "# construct header\n",
    "headers = CaseInsensitiveDict()\n",
    "headers['Authorization'] = f'Bearer {access_token}'\n",
    "headers['Content-Type'] = 'application/json'\n",
    "\n",
    "# construct req body\n",
    "data = ''\n",
    "\n",
    "print(f'Request URL: {request_url}')\n",
    "\n",
    "resp = requests.get(request_url, headers=headers, data=data)\n",
    "content = resp.content.decode('utf-8')\n",
    "c_dict = json.loads(content)\n",
    "print(c_dict['pageDetails']['nextPageUrl'])\n",
    "\n",
    "# iterate and combine remaining pages\n",
    "df_devices = pd.DataFrame(c_dict['devices'])\n",
    "while c_dict['pageDetails']['nextPageUrl']:\n",
    "    next_page = c_dict['pageDetails']['nextPageUrl']\n",
    "    resp = requests.get(next_page, headers=headers, data=data)\n",
    "    content = resp.content.decode('utf-8')\n",
    "    c_dict = json.loads(content)\n",
    "    print(c_dict['pageDetails']['nextPageUrl'])\n",
    "    df_current_page = pd.DataFrame(c_dict['devices'])\n",
    "    df_devices = pd.concat([df_devices, df_current_page], ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Shaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create New Columns from Dictionary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set Index to device UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices.set_index('uid',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Type | Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def device_category(device):\n",
    "    if device is None:\n",
    "        return None\n",
    "    else:\n",
    "        return device['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def device_type(device):\n",
    "    if device is None:\n",
    "        return None\n",
    "    else:\n",
    "        return device['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices['category'] = df_devices['deviceType'].apply(device_category)\n",
    "df_devices['type'] = df_devices['deviceType'].apply(device_type)\n",
    "\n",
    "# Rename 'type' values to split devices into (2) : 'computer' or 'server'\n",
    "#df_devices['type'].replace({'Desktop':'computer','Laptop':'computer','Server':'server'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices.drop(columns='deviceType',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Patch Management Breakdown\n",
    " patchStatus | patchesApprovedPending | patchesNotApproved | patchesInstalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# patchStatus\n",
    "def patch_status(patch_management):\n",
    "    return patch_management['patchStatus']\n",
    "\n",
    "df_devices['patchStatus'] = df_devices['patchManagement'].apply(patch_status)\n",
    "\n",
    "# patchesApprovedPending\n",
    "def patches_approved_pending(patch_management):\n",
    "    return patch_management['patchesApprovedPending']\n",
    "\n",
    "df_devices['patchesApprovedPending'] = df_devices['patchManagement'].apply(patches_approved_pending)\n",
    "\n",
    "# patchesNotApproved\n",
    "def patches_not_approved(patch_management):\n",
    "    return patch_management['patchesNotApproved']\n",
    "\n",
    "df_devices['patchesNotApproved'] = df_devices['patchManagement'].apply(patches_not_approved)\n",
    "\n",
    "# patchesInstalled\n",
    "def patches_installed(patch_management):\n",
    "    return patch_management['patchesInstalled']\n",
    "\n",
    "df_devices['patchesInstalled'] = df_devices['patchManagement'].apply(patches_installed)\n",
    "\n",
    "\n",
    "# drop patchManagement {inplace=True}\n",
    "df_devices.drop('patchManagement',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Drop 'antivirus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices.drop('antivirus',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Time Columns and Timedate Shaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add Timezone Column from UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Timezone\n",
    "def local_timezone(udf):\n",
    "    return udf['udf10']\n",
    "\n",
    "df_devices['localTimezone'] = df_devices['udf'].apply(local_timezone)\n",
    "\n",
    "# drop udf {inplace=True}\n",
    "df_devices.drop('udf',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create Date Correlation Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all date columns\n",
    "parse_dates =  ['lastAuditDate','lastSeen','lastReboot','creationDate',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert Epoch to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices['lastAuditDate'] = pd.to_datetime(df_devices['lastAuditDate'],unit='ms',errors='coerce')\n",
    "#df_devices['lastAuditDate'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices['lastSeen'] = pd.to_datetime(df_devices['lastSeen'],unit='ms',errors='coerce')\n",
    "#df_devices['lastSeen'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices['creationDate'] = pd.to_datetime(df_devices['creationDate'],unit='ms',errors='coerce')\n",
    "#df_devices['creationDate'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices['lastReboot'] = pd.to_datetime(df_devices['lastReboot'],unit='ms',errors='coerce')\n",
    "#df_devices['lastReboot'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define and apply functions to create correlation columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def no_audit_7_days(last_audit):\n",
    "    if last_audit < dt.datetime.now() - dt.timedelta(days=7):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def offline_30_days(last_seen):\n",
    "    if last_seen < dt.datetime.now() - dt.timedelta(days=60):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def no_reboot_60_days(last_reboot):\n",
    "    if last_reboot < dt.datetime.now() - dt.timedelta(days=60):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Column - Devices Last Audit > 7 days\n",
    "df_devices['noAudit7Days'] = df_devices['lastAuditDate'].apply(no_audit_7_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Column - Devices Offline 30 Days\n",
    "df_devices['offline30Days'] = df_devices['lastSeen'].apply(offline_30_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Column - Last Reboot Extended Duration and Online without Reboot Extended Duration\n",
    "df_devices['noReboot60Days'] = df_devices['lastReboot'].apply(no_reboot_60_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create DF copy for reference\n",
    "df_raw_data = df_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DattoRMM DataFrame Data Standardization Shaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hostname to_upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices['hostname'] = df_devices['hostname'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Replace Values {'TRUE':1,'FALSE':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices.replace({True:1,False:0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "convert_to_int = df_devices.dtypes[(df_devices.dtypes == 'float') | (df_devices.dtypes == 'bool') | (df_devices.dtypes == 'uint8')].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices[convert_to_int] = df_devices[convert_to_int].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop Columns with no Data (NaN, 0, or None as only Value on all rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_devices.drop(['lastLoggedInUser','warrantyDate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add 'patchStatus' Dummy Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_patch_status = pd.get_dummies(df_devices['patchStatus'],prefix='patchStatus')\n",
    "df_patch_status.drop('patchStatus_NoPolicy',axis=1, inplace=True)\n",
    "df_devices = df_devices.join(df_patch_status)\n",
    "df_devices.drop('patchStatus',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "username = config['mongodb']['username']\n",
    "password = config['mongodb']['password']\n",
    "connection_ip = config['mongodb']['connection_ip']\n",
    "database = 'seed_data'\n",
    "\n",
    "# import bson for object encoding\n",
    "import bson\n",
    "\n",
    "# Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "#CONNECTION_STRING = f\"mongodb://{username}:{password}@{connection_ip}/{database}\"\n",
    "CONNECTION_STRING = 'mongodb://localhost:27017'\n",
    "\n",
    "\n",
    "# Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "\n",
    "db = client['datto_rmm']\n",
    "collection = db['seed_data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ingest = df_devices.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dt_list = list(df_ingest.dtypes[df_ingest.dtypes == 'datetime64[ns]'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ingest.fillna(pd.NA,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "entries = []\n",
    "cols = enumerate(list(df_ingest.columns))\n",
    "\n",
    "for index, row in df_ingest.iterrows():\n",
    "    current_row = row.to_dict()\n",
    "    new_entry = {}\n",
    "    try:\n",
    "        try:\n",
    "            new_entry['onlineData'] = {'legend':['onlineStatus','lastSeen'],'data':[[current_row['online'],current_row['lastSeen']]]}\n",
    "        except:\n",
    "            print(f'Unable to create column: \"onlineData\"')\n",
    "        try:\n",
    "            if current_row['suspended'] == 1:\n",
    "                new_entry['isSuspended'] = {'legend':['suspendedStatus','lastSeen'],'data':[[current_row['suspended'],current_row['lastSeen']]]}\n",
    "        except:\n",
    "            print(f'Unable to create column: \"isSuspended\"')\n",
    "            print(current_row['suspended'])\n",
    "        try:\n",
    "            if current_row['deleted'] == 1:\n",
    "                new_entry['isDeleted'] = {'legend':['deletedStatus','lastSeen'],'data':[[current_row['deleted'],current_row['lastSeen']]]}\n",
    "        except:\n",
    "            print(f'Unable to create column: \"isDeleted\"')\n",
    "            print(current_row['deleted'])\n",
    "        try:\n",
    "            if current_row['rebootRequired'] == 1:\n",
    "                new_entry['rebootRequired'] = {'legend':['rebootRequired','lastReboot'],'data':[[current_row['rebootRequired'],current_row['lastReboot']]]}\n",
    "        except:\n",
    "            print(f'Unable to create column: \"rebootRequired\"')\n",
    "            print(current_row['rebootRequired'])\n",
    "        for k,v in current_row.items():\n",
    "            if pd.isna(v) == True:\n",
    "                continue\n",
    "            elif (k == 'online') | (k == 'lastSeen') | (k == 'suspended') | (k == 'rebootRequired') | (k == 'lastReboot') |(k == 'deleted'):\n",
    "                continue\n",
    "            else:\n",
    "                new_entry[k] = v\n",
    "\n",
    "        entries.append(new_entry)\n",
    "    except:\n",
    "        print(current_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for entry in entries:\n",
    "    try:\n",
    "        result = collection.find_one({'uid':entry['uid']})\n",
    "        print(f\"_id found: {result['_id']}\")\n",
    "        match_id = result['_id']\n",
    "        for k,v in entry.items():\n",
    "            try:\n",
    "                #print(k,v)\n",
    "                if k in  ['onlineData','isSuspended','isDeleted','rebootRequired']:\n",
    "                    try:\n",
    "                        #print({f\"{ str(k)  + '.legend'}\": v['legend']})\n",
    "                        #collection.insert_one({'_id':m_id}, {f\"{str(k)}\":v['legend']})\n",
    "                        collection.update_one({'_id':match_id},{'$set': {f\"{ str(k)  + '.legend'}\" : v['legend'] }},upsert=False)\n",
    "                        collection.update_one({'_id':match_id},{'$push': {f\"{ str(k)  + '.data'}\" : {\"$each\":  v['data'] }}},upsert=True)\n",
    "                        #print(f\"Successfully updated {k} for {entry['hostname']}\")\n",
    "                    except Exception as error:\n",
    "                        print(error)\n",
    "                else:\n",
    "                    try:\n",
    "                        collection.update_one({'_id':match_id}, {'$set':{f\"{str(k)}\":v}},upsert=True)\n",
    "                        #print(f\"Successfully inserted new {k} for {entries[0]['hostname']}\")\n",
    "                    except Exception as error:\n",
    "                        #print(f\"Unable to insert new {k} for {entries[0]['hostname']}\")\n",
    "                        print(error)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            print(f\"_id not found: attempting new entry for {entry['hostname']} with uid: {entry['uid']}\")\n",
    "            collection.insert_one(entry)\n",
    "        except:\n",
    "            print(e)\n",
    "\n",
    "print('*'*120)\n",
    "print('End of Import!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": "[REDACTED][REDACTED]/.py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
