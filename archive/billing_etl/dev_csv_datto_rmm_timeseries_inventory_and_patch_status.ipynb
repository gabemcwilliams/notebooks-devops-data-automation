{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<h1> DattoRMM - Patching Time Series Inventory </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Modules and Prepare Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# filetype modules\n",
    "import json\n",
    "import csv\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add current timestamp to filename for reference\n",
    "current_time = (dt.datetime.utcnow().strftime('%Y_%m_%d_%H%M%S'))\n",
    "\n",
    "# git repo folder\n",
    "git_folder = 'd:/git/example_infrastructure_data_dev'\n",
    "\n",
    "# export folder will contain all csv exported DataFrames for Ticket Creation\n",
    "export_folder = 'd:/exports/'\n",
    "\n",
    "# define key column to join on\n",
    "fieldnames_to_compare = 'Device UID'\n",
    "\n",
    "# identify folder stages so that files are not called twice in the same stage\n",
    "source_dir = 'D:/cloud_storage/Think Stack/Infrastructure - Documents/Reports - Archiving and Distribution'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import PostgreSQL Modules and Prepare Auth and Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import configparser for env secrets\n",
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(f'{git_folder}/config/env.ini')\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "# import and assign secrets from env.ini\n",
    "postgresql = config['postgresql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define if you are pulling raw data ('data_pool') or test data ('seed_data')\n",
    "database = 'seed_data'\n",
    "\n",
    "# DEFINE THE DB URI\n",
    "db_uri = f\"postgresql://{postgresql['username']}:{postgresql['password']}@{postgresql['uri']}:{postgresql['port']}/{database}\"\n",
    "\n",
    "# DEFINE THE ENGINE (CONNECTION OBJECT)\n",
    "engine = create_engine(db_uri, echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary of df_names and queries used to create dataframes from postreSQL\n",
    "device_details = {'dataframe':'df_device_details','query':'SELECT * FROM datto_rmm.device_details'}\n",
    "os_patch_mgmt = {'dataframe':'df_os_patch_mgmt','query':'SELECT * FROM datto_rmm.os_patch_mgmt'}\n",
    "\n",
    "import_dataframes = [device_details,os_patch_mgmt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pull all Historical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pull list of all csv and xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pull all filenames walking through all folders (recursive going down the tree)\n",
    "#all_source_csv = []\n",
    "source_report = []\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if ('.csv' in file) | ('.xlsx' in file):\n",
    "            info_dict = {}\n",
    "            info_dict['filename'] = os.path.join(file)\n",
    "            info_dict['fullPath'] = os.path.join(root,file)\n",
    "            source_report.append(info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create Dataframe of files and lcoations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files = pd.DataFrame(source_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sort out those files that have words that signify a patch report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patch_file_prog = re.compile(r'[pP]atch')\n",
    "third_prog = re.compile(r'(\\b3rd\\b|\\b3PP\\b)+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_patching_reports(filename):\n",
    "    patch_result = patch_file_prog.findall(filename)\n",
    "    software_result = third_prog.findall(filename)\n",
    "    if (software_result == []) & (patch_result != []):\n",
    "        return filename\n",
    "    else:\n",
    "        return 'Remove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['filename'] = df_files['filename'].apply(find_patching_reports)\n",
    "df_files = df_files[df_files['filename'] != 'Remove']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare and Standardize Data Ingestion Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Break out year and month of the report into seperate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Iterate through month names and replace with number if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "month_dict = {'January': '01', 'February': '02', 'March': '03', 'April': '04', 'May': '05', 'June': '06', 'July': '07','August': '08', 'September': '09', 'October': '10', 'November': '11', 'December': '12'}\n",
    "def transform_month_to_number(month):\n",
    "\n",
    "    for k, v in month_dict.items():\n",
    "\n",
    "        result = re.sub(k,v,month)\n",
    "        if result != month:\n",
    "            return (result)\n",
    "            break\n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['adjustedFileName'] = df_files['filename'].apply(transform_month_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Functions to break apart month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "report_year_prog = re.compile(r'\\s{1}(\\d{4})')\n",
    "report_month_prog = re.compile(r'\\s{1}(\\d{2})\\s{1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def report_date_year(file):\n",
    "    try:\n",
    "        result = report_year_prog.search(file)\n",
    "\n",
    "        return (result[0])\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "def report_date_month(file):\n",
    "    try:\n",
    "        result = report_month_prog.search(file)\n",
    "        return (result[0])\n",
    "    except:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['reportYear'] = df_files['adjustedFileName'].apply(report_date_year)\n",
    "df_files['reportMonth'] = df_files['adjustedFileName'].apply(report_date_month)\n",
    "df_files.drop('adjustedFileName',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Standardize Client Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client_name_prog = re.compile(r'^([^\\-]+)\\s')\n",
    "clients_set = set()\n",
    "\n",
    "def client_names(file):\n",
    "    result = client_name_prog.findall(file)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['clientName'] = df_files['filename'].apply(client_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'.csv')\n",
    "client_rename_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    [REDACTED] = row['[REDACTED]']\n",
    "    currentName = row['currentName']\n",
    "    client_rename_dict[[REDACTED]] = currentName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['clientName'].replace(client_rename_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Timestamp Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def AddTime(source_file):\n",
    "    source_mfdate = 'Source Modified Date'\n",
    "    source_crdate = 'Source Creation Date'\n",
    "    source_fn = 'Source Filename'\n",
    "\n",
    "    # Both the variables would contain time\n",
    "    # elapsed since EPOCH in float\n",
    "    ti_c = os.path.getctime(source_file)\n",
    "    ti_m = os.path.getmtime(source_file)\n",
    "    fi_n = os.path.basename(source_file)\n",
    "\n",
    "\n",
    "    # Converting the time in seconds to UTC datetime\n",
    "    c_ti = dt.datetime.utcfromtimestamp(ti_c).strftime('%Y/%m/%d %H:%M:%S')\n",
    "    m_ti = dt.datetime.utcfromtimestamp(ti_m).strftime('%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "\n",
    "    return {source_crdate:c_ti,source_mfdate:m_ti,source_fn:fi_n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['sourceData'] = df_files['fullPath'].apply(AddTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def creation_date(sourceData):\n",
    "    return sourceData['Source Creation Date']\n",
    "\n",
    "def modified_date(sourceData):\n",
    "    return sourceData['Source Modified Date']\n",
    "\n",
    "def source_filename(sourceData):\n",
    "    return sourceData['Source Filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['sourceCreationDate'] = df_files['sourceData'].apply(creation_date)\n",
    "df_files['sourceModifiedDate'] = df_files['sourceData'].apply(modified_date)\n",
    "df_files['sourceFilename'] = df_files['sourceData'].apply(source_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files.drop('sourceData',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_cols_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for path in df_files.iloc[0]['fullPath']:\n",
    "    print(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        df_cols_count.update(df.columns)\n",
    "    except:\n",
    "        print('cannot load csv')\n",
    "        try:\n",
    "            df = pd.read_excel(path)\n",
    "            df_cols_set.update(df.columns)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_cols_set.update(df_files.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(df_files.iloc[0]['fullPath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_cols_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Break out Data by System Creator (Automate, DattoRMM, Sophos, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": "pd.DataFrame(clients_set).to_csv('.csv')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": "df_files.to_csv('.csv')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['reportYear'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files[df_files['filename'].str.contains('March')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_files['reportMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "march = df_files[df_files['filename'].str.contains('March')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "march.iloc[:]['filename'] = march['filename'].apply(transform_month_to_number)\n",
    "march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "march['reportYear'] = march['filename'].apply(report_date_year)\n",
    "march['reportMonth'] = march['filename'].apply(report_date_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "march = df_files[df_files['filename'].str.contains('March')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "help = transform_month_to_number(str(march['filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "re.sub('March','03','[REDACTED] - March 2022.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Sorting and Excluding Files</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read all csv file columns and create two lists of files:\n",
    "### Those with the chosen merge key column will be kept and the remaining filenames will not be called any further"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "filename = ''\n",
    "\n",
    "for k,v in source_csv_dict.items():\n",
    "    df = pd.read_csv(v)\n",
    "    #print(df['Site Name'].unique())\n",
    "    #compare_keys(df,filename)\n",
    "    if fieldnames_to_compare not in df.columns:\n",
    "        print(f'Missing Key: {fieldnames_to_compare} to Join in {filename}')\n",
    "        excluded_files.update({k:v})\n",
    "    else:\n",
    "        included_files.update({k:v})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "print('Files with CORRECT join key column:')\n",
    "print('-'*50)\n",
    "for file in included_files:\n",
    "    print(file)\n",
    "print('='*50)\n",
    "\n",
    "print('Files MISSING join key column:')\n",
    "print('-'*50)\n",
    "for file in excluded_files:\n",
    "    print(file)\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parse Accepted Reports for file discription and store as dictionary key pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "string = 'ExampleFCU - 2020 - 11 - Patching Audit.xlsx'\n",
    "ms_patch_prog = re.compile(r'(\\bSIG\\b|\\bExampleFCU\\b|\\bExample FCU\\b){1}.*(?!\\b3rd\\b)+(\\bMS\\b|\\bPatch\\b|\\bPatching\\b)+')\n",
    "third_prog = re.compile(r'(\\b3rd\\b|\\b3PP\\b)+')\n",
    "extension_prog = re.compile(r'(\\.\\w{3,4})')\n",
    "report_date_prog = re.compile(r'(\\d{4}).*(\\d{2})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ms_patch_reports = []\n",
    "for k,v in source_report_dict.items():\n",
    "    match = {}\n",
    "\n",
    "    if (ms_patch_prog.search(k) != None) & (third_prog.search(k) == None):\n",
    "\n",
    "        # date nested dict\n",
    "        date = {}\n",
    "        date['year'] = str(report_date_prog.findall(k)[0][0])\n",
    "        date['month'] = str(report_date_prog.findall(k)[0][1])\n",
    "\n",
    "        match['filename'] = k\n",
    "        match['path'] = v\n",
    "\n",
    "        # extension\n",
    "        if extension_prog.findall(file['filename']) == ['.xlsx']:\n",
    "            match['extension'] = 'xlsx'\n",
    "\n",
    "        elif extension_prog.findall(file['filename']) == ['.csv']:\n",
    "            match['extension'] = 'csv'\n",
    "\n",
    "        match['date'] = date\n",
    "\n",
    "        ms_patch_reports.append(match)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "# Export the originals (will delete timestamp)\n",
    "import shutil\n",
    "for file in ms_patch_reports:\n",
    "    shutil.copyfile(file['path'], f\"d:/exports/{file['filename']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## For those files that have the key column, set index col and add source info\n",
    "### 1. Add source file data as columns at end of dataframe (record the file creation, modified, and fullpath name)\n",
    "### 2. Set index col = fieldnames_to_compare variable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "def AddTime(source_file):\n",
    "    source_mfdate = 'Source Modified Date'\n",
    "    source_crdate = 'Source Creation Date'\n",
    "    source_fn = 'Source Filename'\n",
    "\n",
    "    # Both the variables would contain time\n",
    "    # elapsed since EPOCH in float\n",
    "    ti_c = os.path.getctime(source_file)\n",
    "    ti_m = os.path.getmtime(source_file)\n",
    "    fi_n = os.path.basename(source_file)\n",
    "\n",
    "\n",
    "    # Converting the time in seconds to UTC datetime\n",
    "    c_ti = datetime.datetime.utcfromtimestamp(ti_c).strftime('%Y/%m/%d %H:%M:%S')\n",
    "    m_ti = datetime.datetime.utcfromtimestamp(ti_m).strftime('%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "\n",
    "    return {source_crdate:c_ti,source_mfdate:m_ti,source_fn:fi_n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def map_source(source_file):\n",
    "    # pull source time from file properties\n",
    "    source_info = AddTime(source_file)\n",
    "\n",
    "    # Import CSV\n",
    "    df = pd.read_csv(source_file,index_col=fieldnames_to_compare)\n",
    "\n",
    "    # add source info to new columns k with values v\n",
    "    for k,v in source_info.items():\n",
    "        df[k] = v\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_csv.to_sql('test_db', con=engine, if_exists='append',index=False,schema='datto_rmm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
