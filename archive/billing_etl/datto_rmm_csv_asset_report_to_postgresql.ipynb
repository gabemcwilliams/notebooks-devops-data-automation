{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>CSV to PostgreSQL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare for Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import modules and declare globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#data conditioning\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "# data import and file manipulation\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "import pyarrow\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# add current timestamp to filename for reference\n",
    "current_time = (dt.datetime.utcnow().strftime('%Y_%m_%d_%H%M%S'))\n",
    "\n",
    "# git repo folder\n",
    "git_dir = 'd:/git'\n",
    "\n",
    "# dictionary location\n",
    "dict_dir = f'{git_dir}/data_parsing/dictionaries'\n",
    "\n",
    "# export folder will contain all csv exported DataFrames for Ticket Creation\n",
    "data_source_dir = 'D:/data_sets/billing_archive/data'\n",
    "export_dir = 'D:/data_sets/billing_archive/exports'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pull source file data and worksheet tab names to compile for data targetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_source_dir):\n",
    "    for file in files:\n",
    "        source_files.append(root + \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sheet_names = {}\n",
    "for file in source_files:\n",
    "    workbookData = openpyxl.load_workbook(file)\n",
    "    for name in workbookData.sheetnames:\n",
    "        temp_dict = {name: sheet_names.get(name, 0) + 1}\n",
    "        sheet_names.update(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Import and Shaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Clean and Standardize Dataframe Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import dictionaries for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "service_names_dict = pd.read_parquet(f'{dict_dir}/billing_worksheet.parquet', engine='auto').to_dict(orient='records')\n",
    "\n",
    "rmm_source_tabs = []\n",
    "for s in service_names_dict:\n",
    "    if s['service'] == 'rmm':\n",
    "        rmm_source_tabs.append(s['orig_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client_rename_dict = pd.read_parquet(f\"{dict_dir}/standard_client_names.parquet\", engine='auto').to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "months_dict = pd.read_parquet(f\"{dict_dir}/date_naming_conversions.parquet\", engine='auto').to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define Functions for Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove the offboard from CLIENT names that were once used to signify a client was offboarded as an explanation for missing data going forward\n",
    "def remove_offboard(string):\n",
    "    offboarded_list = [\" - Offboarded\",\" - Off-Boarded\",\" \\(Offboarded\\)\"]\n",
    "    for word in offboarded_list:\n",
    "        result = re.sub(word,\"\",string)\n",
    "        if result != string:\n",
    "            string = result\n",
    "            break\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rename all CLIENT name entries with known standardized names using dictionary and substitution logic\n",
    "def rename_client(string):\n",
    "    for c in client_rename_dict:\n",
    "\n",
    "        #compare exact match on lowercase\n",
    "        if c['[REDACTED]'].lower() == string.lower():\n",
    "                    string = c['currentName']\n",
    "                    break\n",
    "        # must restrict <= 4 characters to strings that are of size or contain hyphens and uppercase, else there are too many combos\n",
    "        if len(c['[REDACTED]']) <= 4:\n",
    "            result = re.sub(c['[REDACTED]'], c['currentName'], string)\n",
    "            # print(\"k: \" + k + \" v: \" + v + \"\\nsting: \" + string + \"\\n\")\n",
    "            if (result.lower() != string.lower()) & ((len(string) <= len(c['[REDACTED]']) + 4) | (\" - \" in string)):\n",
    "                string = c['currentName']\n",
    "                break\n",
    "        else:\n",
    "            result = re.sub(c['[REDACTED]'].lower(), c['currentName'], string.lower())\n",
    "            if result != string.lower():\n",
    "                string = c['currentName']\n",
    "                break\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# strip superfluous words (ie. (offboard)) from cells that would normally only contain digits (string to strip then to digit)\n",
    "def strip_words_from_digit_cols(string):\n",
    "    result = re.search(r'\\d+',str(string))\n",
    "    # print(result)\n",
    "    if result is not None:\n",
    "        result = result.group(0).lstrip().rstrip()\n",
    "        string = result\n",
    "\n",
    "    return int(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create aggregate filter to be used when adding rows with the same CLIENT name column on column\n",
    "def agg_group(dataframe):\n",
    "    date_cols = list(dataframe.columns[1:])\n",
    "    agg_filter = {}\n",
    "    for col in date_cols:\n",
    "        agg_filter.update({col: \"sum\"})\n",
    "\n",
    "    return agg_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Iterate over worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for x in source_files:\n",
    "    tab_names = openpyxl.load_workbook(x).sheetnames # pull all sheet names in workbook\n",
    "    year = (re.search(r'\\d+',x)).group(0)\n",
    "    print(x)\n",
    "    selected_tabs = (list(set(tab_names).intersection(rmm_source_tabs)))[0] # mark against known sheet names that were parsed against current sheet list to find target sheet\n",
    "    print(selected_tabs)\n",
    "    df = pd.read_excel(x, sheet_name=selected_tabs, header=1) # import excel and start header with row 1\n",
    "    df = df.dropna(thresh=3).dropna(thresh=3, axis=1) # drop empty rows or cols with > 3 NAN values\n",
    "    client_col_index = df.columns.get_loc(\"CLIENT\") # find CLIENT heading index as known standard for client name data\n",
    "    # if client_col_index < 0: client_col_index = 0 # set CLIENT index is 0 leave else\n",
    "    df = df.drop(df.iloc[:, :client_col_index],axis = 1)\n",
    "    client_col = df.columns[0] # Define name for client column (most likely CLIENT but this is the left most column after dropping empty rows/cols)\n",
    "    df[client_col].fillna('Total',inplace=True) # Fill known NAN CLIENT name with 'Total'\n",
    "    df[client_col] = df[client_col].apply(remove_offboard) # remove 'offboard' related wording from client names\n",
    "    df[client_col] = df[client_col].apply(rename_client) # start client renaming substitution function\n",
    "    df.fillna(0,inplace=True) # fill all date column cell values that are NAN with 0\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = df[col].apply(strip_words_from_digit_cols) # iterate down each column stripping all non-digit characters and replace with int(str) values\n",
    "    df = df.groupby('CLIENT').agg(agg_group(df)).reset_index() # aggregate using sum on all rows that contain equal CLIENT names\n",
    "\n",
    "    df = df[~df['CLIENT'].isin(['TOTAL','Total','Monthly Delta'])] # Drop Totals so they can be recalculated using pandas\n",
    "\n",
    "    #Total sum per column:\n",
    "    month_sums = dict(df[df.columns[1:]].sum(axis=0))\n",
    "    month_sums.update({\"CLIENT\":\"Total Agents\"})\n",
    "    df = pd.concat([df, pd.DataFrame.from_records([month_sums])], ignore_index=True)\n",
    "    df_list.append({\"year\":year,\"file\":x,\"dataframe\":df}) # append both filename and dataframe to df_list for further action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Convert Date Shorthand Column names to Datetime and Transpose to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parse and rename date column names to datetime before transpose to index row markers\n",
    "def months_rename(df_object):\n",
    "    rename_dict = {}\n",
    "    print( list(df_object['dataframe'].columns[1:]))\n",
    "    for col in list(df_object['dataframe'].columns[1:]):\n",
    "        for m in months_dict:\n",
    "            month = \"NOT FOUND\"\n",
    "            # compare exact match on lowercase\n",
    "            if m['abcr'].lower() == col.lower():\n",
    "                month = int(m['monthNumber'])\n",
    "                break\n",
    "\n",
    "            result = re.search(m['abcr'].lower(), col.lower())\n",
    "            if result:\n",
    "                month = int(m['monthNumber'])\n",
    "                break\n",
    "\n",
    "        date = dt.datetime(int(df_object['year']), month, int(m['lastDay'])).strftime(\"%Y-%m-%d\")\n",
    "        rename_dict.update({col:date})\n",
    "\n",
    "    return rename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_transposed_list = []\n",
    "for df_obj in df_list:\n",
    "    df = df_obj['dataframe'].rename(columns=months_rename(df_obj))\n",
    "    df = df.transpose()\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[0], axis=0, inplace=True)\n",
    "    df.drop(\"Monthly Delta\",axis=1,errors='ignore', inplace=True)\n",
    "    df.rename({\"Total\":\"Total Agents\",\"TOTAL\":\"Total Agents\"},axis=1,errors='ignore',inplace=True)\n",
    "    df_transposed_list.append(df)\n",
    "\n",
    "# concat all transposed df into one\n",
    "df = pd.concat(df_transposed_list, ignore_index=False)\n",
    "\n",
    "# reorder columns\n",
    "columns_list = list(df.columns)\n",
    "columns_list.remove('Total Agents')\n",
    "columns_list.sort()\n",
    "columns_list.insert(0,'Total Agents')\n",
    "\n",
    "df = df[columns_list]\n",
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": "df.to_csv(f'{export_dir}.csv')"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Display Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create Sites DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_sites = df.drop(['Total Agents'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Timeseries plot of DataFrame - Total Agents\n",
    "fig = plt.figure(figsize=(100,40))\n",
    "sns.lineplot(data=df,x=df.index, y='Total Agents')\n",
    "fig.savefig(f'{export_dir}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "columns_plot = df_sites.columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(100,40))\n",
    "ax.yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "for each in columns_plot:\n",
    "    sns.lineplot(data = df_sites, x = df_sites.index, y = each, label = str(each), errorbar=None)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(f'{export_dir}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
