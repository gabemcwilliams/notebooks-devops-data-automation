{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc5e3a584679eb9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1> Datto RMM - CSV import - Filter by deviceID - Shape - Export to PostgreSQL </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e858045209828",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Modules and Define Functions\n",
    "## Import Modules\n",
    "### Import DataFrame and Shaping Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81cebf2e06cf31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "\n",
    "# import configparser for env secrets\n",
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read('d:/git/example_infrastructure_data_dev/config/env.ini')\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c072d8b79168243",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import PostgreSQL Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c3d2afc33ea3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070e99f09d3a74c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import and assign secrets from env.ini\n",
    "\n",
    "# postgreSQL\n",
    "username = config['postgresql']['username']\n",
    "password = config['postgresql']['password']\n",
    "uri = config['postgresql']['uri']\n",
    "port = config['postgresql']['port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cffbc56ed5b28e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define if you are pulling raw data ('data_pool') or test data ('seed_data')\n",
    "database = 'seed_data'\n",
    "\n",
    "# exclude csv if missing column name\n",
    "exclude_on_missing_column = False\n",
    "\n",
    "# DEFINE THE DB URI\n",
    "db_uri = f'postgresql://{username}:{password}@{uri}:{port}/{database}'\n",
    "\n",
    "# DEFINE THE ENGINE (CONNECTION OBJECT)\n",
    "engine = create_engine(db_uri, echo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23978e16d1bfc72",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b827596e81cc24b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "def add_time(source_file):\n",
    "    source_mfdate = 'Source Modified Date'\n",
    "    source_crdate = 'Source Creation Date'\n",
    "    source_fn = 'Source Filename'\n",
    "\n",
    "    # Both the variables would contain time\n",
    "    # elapsed since EPOCH in float\n",
    "    ti_c = os.path.getctime(source_file)\n",
    "    ti_m = os.path.getmtime(source_file)\n",
    "    fi_n = os.path.basename(source_file)\n",
    "\n",
    "    # Converting the time in seconds to UTC datetime\n",
    "    c_ti = datetime.datetime.utcfromtimestamp(ti_c).strftime('%Y/%m/%d %H:%M:%S')\n",
    "    m_ti = datetime.datetime.utcfromtimestamp(ti_m).strftime('%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "\n",
    "    return {source_crdate:c_ti,source_mfdate:m_ti,source_fn:fi_n}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb45c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Arguments and Declarations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a488d389549a7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define Source and Export Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f6890f5e87127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# identify folder stages so that files are not called twice in the same stage\n",
    "source_dir = 'D:/users/gmcwilliams/downloads/'\n",
    "# source_dir = 'D:\\cloud_storage\\OneDrive - Think Stack\\Reports Automation'\n",
    "\n",
    "# export folder will contain all csv exported DataFrames\n",
    "export_folder = 'd:/exports/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47833719499fe566",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define Current Time of Script Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ea2e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add current timestamp to filename for reference\n",
    "current_time = (dt.datetime.utcnow().strftime('%Y_%m_%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d871d2bfa6e7f7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize and Define Structure and Containers for Data Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a351a10d028a16b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define key column to join on\n",
    "fieldnames_to_compare = 'Device UID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda21494",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary of df_names and queries used to create tables in postreSQL\n",
    "device_details = {'dataframe':'device_details','query':'SELECT * FROM datto_rmm.device_details'}\n",
    "os_patch_mgmt = {'dataframe':'os_patch_mgmt','query':'SELECT * FROM datto_rmm.os_patch_mgmt'}\n",
    "\n",
    "import_dataframes = [device_details,os_patch_mgmt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516419d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Selected Columns from Master Device View Export CSV - This is the column mask that will be used to trimp the outer merge on match key column\n",
    "std_columns = [\n",
    "    'Device UID',\n",
    "    'Site Name',\n",
    "    'Site UID',\n",
    "    'Device Hostname',\n",
    "    'Create Date',\n",
    "    'Last Seen',\n",
    "    'Last Audit Date',\n",
    "    'Policy',\n",
    "    'Patches Approved Pending',\n",
    "    'Patches Not Approved',\n",
    "    'Patches Installed',\n",
    "    'Patch Status',\n",
    "    'Schedule',\n",
    "    'Last Run',\n",
    "    'Operating System',\n",
    "    'Device CPU',\n",
    "    'Physical CPU Cores',\n",
    "    '.NET Version',\n",
    "    'Memory',\n",
    "    'Device Type',\n",
    "    'Domain',\n",
    "    'Disk Drive (total/free)',\n",
    "    'Online Duration (hrs)',\n",
    "    'Architecture',\n",
    "    'Last Reboot',\n",
    "    'Reboot required',\n",
    "    'Int IP Address',\n",
    "    'User-Defined Field 10',\n",
    "    'MAC Address(es)',\n",
    "    'Software Status',\n",
    "    'Group',\n",
    "    'Antivirus Product',\n",
    "    'Antivirus Status',\n",
    "    'Source Modified Date',\n",
    "    'Source Creation Date',\n",
    "    'Source Filename'\n",
    "]\n",
    "\n",
    "device = [\n",
    "    'Device UID',\n",
    "    'Device Hostname',\n",
    "    'Site UID',\n",
    "    'Site Name',\n",
    "    'Device Description',\n",
    "    'Int IP Address',\n",
    "    'Ext IP Addr',\n",
    "    'Create Date',\n",
    "    'Last Seen',\n",
    "    'Last Audit Date',\n",
    "    'Session Name',\n",
    "    'Privacy Mode',\n",
    "    'Agent Version',\n",
    "    'Device Model',\n",
    "    'Operating System',\n",
    "    'Serial Number',\n",
    "    'Motherboard',\n",
    "    'Device CPU',\n",
    "    'Physical CPU Cores',\n",
    "    '.NET Version',\n",
    "    'Memory',\n",
    "    'MAC Address(es)',\n",
    "    'User-Defined Field 10',\n",
    "    'Device Type',\n",
    "    'Domain',\n",
    "    'Disk Drive (total/free)',\n",
    "    'Online Duration (hrs)',\n",
    "    'Architecture',\n",
    "    'BIOS Name',\n",
    "    'BIOS Release Date',\n",
    "    'BIOS Version',\n",
    "    'Last Reboot',\n",
    "    'Reboot required',\n",
    "    'Manufacturer',\n",
    "]\n",
    "\n",
    "manage = [\n",
    "    'Device UID',\n",
    "    'Site Name',\n",
    "    'Device Hostname',\n",
    "    'Device Description',\n",
    "    'Policy',\n",
    "    'Int IP Address',\n",
    "    'Ext IP Addr',\n",
    "    'Last User',\n",
    "    'Group',\n",
    "    'Create Date',\n",
    "    'Last Seen',\n",
    "    'Last Audit Date',\n",
    "    'Session Name',\n",
    "    'Agent Version',\n",
    "    'Operating System',\n",
    "    'Service Pack',\n",
    "    'Serial Number',\n",
    "    'User-Defined Field 10',\n",
    "    'Last Run',\n",
    "    'Schedule',\n",
    "    'Patch Status',\n",
    "    'Patches Approved Pending',\n",
    "    'Patches Installed',\n",
    "    'Patches Not Approved',\n",
    "    'Device Type',\n",
    "    'Domain',\n",
    "    'Disk Drive (total/free)',\n",
    "    'Online Duration (hrs)',\n",
    "    'Last Reboot',\n",
    "    'Reboot required',\n",
    "    'Manufacturer'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375794c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# output of csv with matching key column\n",
    "included_files = {}\n",
    "\n",
    "# output csv of all files that could not be merged\n",
    "excluded_files = {}\n",
    "\n",
    "# Regex Match to group files to be combined on rows rather than merged on columns to prevent dropping rows if there isnt a key column match when files are combined in random order\n",
    "pattern = re.compile(r'^(\\w+)_')\n",
    "\n",
    "# CSV File Types\n",
    "devices_tab_export_filename = 'DeviceDetailsExport'\n",
    "manage_tab_export_filename = 'SystemDeviceSelection'\n",
    "grouped_export_files_list = []\n",
    "shaped_df_object_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281d584",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read all files in source_dir and sub directories\n",
    "## Filter by '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69708223",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pull all filenames walking through all folders (recursive going down the tree)\n",
    "source_csv_dict = {}\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if '.csv' in file:\n",
    "            source_csv_dict.update({os.path.join(file):os.path.join(root,file)})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15734d1bd379298d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(all_source_csv)\n",
    "print('All CSV Files found before futher vetting and filtering')\n",
    "print('='*50)\n",
    "for k,v in source_csv_dict.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0929a04f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sorting and Excluding Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa36227",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read all csv file columns and create two lists of files:\n",
    "### Those with the chosen merge key column will be kept and the remaining filenames will not be called any further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90275a2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k,v in source_csv_dict.items():\n",
    "    if exclude_on_missing_column == True:  \n",
    "        df = pd.read_csv(v)\n",
    "        if fieldnames_to_compare not in df.columns:\n",
    "            print(f'Missing Key: {fieldnames_to_compare} to Join in {k}')\n",
    "            excluded_files.update({k:v})\n",
    "        else:\n",
    "            included_files.update({k:v})\n",
    "    else:\n",
    "        included_files.update({k:v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df54d604a02b5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Files with CORRECT join key column:')\n",
    "print('-'*50)\n",
    "for file in included_files:\n",
    "    print(file)\n",
    "print('='*50)\n",
    "\n",
    "print('Files MISSING join key column:')\n",
    "print('-'*50)\n",
    "for file in excluded_files:\n",
    "    print(file)\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70e264",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parse Accepted CSV's for file discription and store as dictionary key pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de4a5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'^([a-zA-Z]{0,})(\\_|\\-|''){0,1}([a-zA-Z]{0,})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5ce39a9f19d81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k,v in included_files.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccc1a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k,v in included_files.items():\n",
    "    matches = pattern.search(k)\n",
    "    if matches[1] == devices_tab_export_filename:\n",
    "        #print(f'''['{v}'] matches: ['{devices_tab_export_filename}'] on ['{matches[1]}']''')\n",
    "        grouped_export_files_list.append({'filename':v,'groupname':'device_details','columns':device})\n",
    "    elif matches[3] == manage_tab_export_filename:\n",
    "        #print(f'''['{v}'] matches: ['{manage_tab_export_filename}'] on ['{matches[3]}']''')\n",
    "        grouped_export_files_list.append({'filename':v,'groupname':'os_patch_mgmt','columns':manage})\n",
    "\n",
    "    \n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46298068b766aad5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k in grouped_export_files_list:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fdf88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## For those files that have the key column, shape add source info\n",
    "\n",
    "### 1. Add in any missing columns against the standard so data columns line up on import\n",
    "### 3. Trim extra df columns to match column standards\n",
    "### 4. Replace any known type mismatch values before setting datetime\n",
    "### 5. Add source file data as columns at end of dataframe (record the file creation, modified, and fullpath name)\n",
    "### 6. Parse known date columns to datetime so the types are correct in db import\n",
    "### 7. EXPORT to postregsql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948047c0d34c7c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb542d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in grouped_export_files_list:\n",
    "    filename = file['filename']\n",
    "    groupname = file['groupname']\n",
    "    grp_columns = file['columns']\n",
    "\n",
    "\n",
    "    # pull source time from file properties\n",
    "    source_info = add_time(filename)\n",
    "\n",
    "\n",
    "    # NA Values Check\n",
    "    na_values = ['Currently Online','null', '(null)']\n",
    "\n",
    "\n",
    "    # Import CSV to Pandas\n",
    "    print(f\"reading file ['{filename}'] and ['{groupname}']!\")\n",
    "    #,index_col=['Device UID','Source Modified Date']\n",
    "    df = pd.read_csv(filename,na_values=na_values,skipinitialspace=True)\n",
    "\n",
    "\n",
    "    # if column is missing in dataframe add it before upload to prevent mismatch or multi indexed columns\n",
    "    for c in grp_columns:\n",
    "        if c not in df:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    # DTYPES\n",
    "\n",
    "    # prepare DTYPE values to match predicted values - get column initial dtypes\n",
    "    column_dtypes = dict(df.dtypes)\n",
    "\n",
    "    for k,v in column_dtypes.items():\n",
    "\n",
    "        # strip any whitespace from object columns (non-datetime or boolean)\n",
    "        if v == 'object':\n",
    "            df[k].str.strip()\n",
    "\n",
    "        # Condition boolean values for postgreSQL: (True,False,NULL) Only!\n",
    "        elif v == 'bool':\n",
    "            df[k].mask(df[k] == '', pd.NA, inplace=True)\n",
    "\n",
    "    # regex remove whitespace\n",
    "    df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "\n",
    "\n",
    "    # Replacement Values for type mismatch\n",
    "    replace_dict = {\n",
    "        'Currently Online':source_info['Source Modified Date'],\n",
    "        '':pd.NA\n",
    "    }\n",
    "    df.replace(replace_dict)\n",
    "\n",
    "\n",
    "    # drop non-standard columns\n",
    "    df.drop([col for col in df.columns if col not in grp_columns], axis=1, inplace=True)\n",
    "    #print(f'columns after drop: {df.columns}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # add source info to new columns k with values v\n",
    "    for k, v in source_info.items():\n",
    "        df[k] = v\n",
    "\n",
    "\n",
    "    # Parse Date Data Options\n",
    "    date_parser = lambda c: pd.to_datetime(c, errors='coerce')\n",
    "    parse_dates =  [\n",
    "        'Create Date',\n",
    "        'Last Seen',\n",
    "        'Last Reboot',\n",
    "        'Source Creation Date',\n",
    "        'Source Modified Date'\n",
    "    ]\n",
    "\n",
    "    # filename prefix timestamp format\n",
    "    time_format = '%Y_%m_%d_%H%M%S'\n",
    "\n",
    "\n",
    "    # convert dates to datetime\n",
    "    df[parse_dates] = df[parse_dates].apply(date_parser)\n",
    "\n",
    "\n",
    "    # section can be uncommented for seed data creation for import on a new table to set column names and types\n",
    "    #df.to_csv(export_folder + 'csv_ingress_' + str(current_time) + '.csv')\n",
    "    df.to_json(export_folder + 'csv_ingress_' + str(current_time) + '.json')\n",
    "\n",
    "\n",
    "    # export to postgresql\n",
    "    #df.to_sql(groupname, con=engine, if_exists='replace',  schema='datto_rmm')\n",
    "    print('='*100)\n",
    "    print('')\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd8937",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": "[REDACTED][REDACTED][REDACTED]/.py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
